{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww16860\viewh11200\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs28 \cf0 This post provides a tour around Pytorch with a specific focus on building a simple multilayer perceptron to classify two classes in some toy data. My goal is to introduce some of pytorch\'92s basic building blocks, whilst also highlighting how deep learning can be used to learn non-linear functions. All of the code for this post is here.\
\
I have now experimented with several deep learning frameworks - tensorflow, keras, mxnet - but, pytorch has recently become my tool of choice. This isn\'92t because I think it is objectively better than other frameworks, but more that it *feels* more suited to my style of programming and learning. \
\
## Getting started\
To follow along make sure you have pytorch installed on your machine. Note that I am using version ****. The next version of pytorch will introduce some breaking changes (read about them here). \
 \
The learning task for this post will be to classify points in half moon shapes. This is a rather simple task for a deep learning model, but it serves to highlight their ability to learn complex, non-linear functions. For example, if we use a logistic regression to classify this data look what happens:\
\
Despite applying a softmax transformation to the predicted outputs (squeezing predicted output logits to sum to 1), the logistic regression is linear in its parameters and, therefore, struggles to learn non-linear relationships. We could use a more advanced ML model for this task, such as a random forest, but then we wouldn\'92t have an excuse to play around with a neural network!\
\
Before building the model, we will first create a custom data pre-processor and loader. In this example, the transformer will simply X and y from numpy arrays to pytorch tensors. We will then use the dataloader class to handle how data is passed through the model. In this instance we will set-up a minibatch routine. This means that during each epoch the model will x\
\
The standard approach to defining a deep learning model with pytorch is to encapsulate the network in a class. I quite like this approach because because it ensures that all layers, data, and methods are accessible from a single object. \
\
\
\
\
\
}